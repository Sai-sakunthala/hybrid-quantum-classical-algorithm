{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNDCyvnXtiARETq3kNDSCoq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sai-sakunthala/hybrid-quantum-classical-algorithm/blob/main/term_paper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2GL8JfdATLI",
        "outputId": "cf194705-5f2e-4bd0-e115-b0237ab8edfc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.1/56.1 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m84.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m930.8/930.8 kB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m76.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m70.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m101.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install pennylane torch --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pennylane as qml\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "# Set up device\n",
        "n_qubits = 2\n",
        "n_shots = 5000\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits, shots=n_shots)\n",
        "\n",
        "@qml.qnode(dev)\n",
        "def bell_sampler():\n",
        "    qml.Hadamard(wires=0)\n",
        "    qml.CNOT(wires=[0, 1])\n",
        "    return qml.sample(qml.PauliZ(0)), qml.sample(qml.PauliZ(1))\n",
        "\n",
        "@qml.qnode(dev, interface=\"torch\")\n",
        "def bell_basis_sampler():\n",
        "    # creating bell state\n",
        "    qml.Hadamard(wires=0)\n",
        "    qml.CNOT(wires=[0, 1])\n",
        "\n",
        "    # computational basis changed to eigen basis\n",
        "    qml.CNOT(wires=[0, 1])\n",
        "    qml.Hadamard(wires=0)\n",
        "\n",
        "    return qml.sample(wires=[0, 1])\n",
        "\n",
        "def get_bell_samples():\n",
        "    samples = bell_basis_sampler()\n",
        "    return samples.to(torch.float32)\n",
        "\n",
        "def get_custom_mixed_samples(n_samples=5000):\n",
        "    samples = torch.zeros((n_samples, 2), dtype=torch.float32)\n",
        "    probs = torch.rand(n_samples)\n",
        "    samples[probs >= 0.7] = torch.tensor([1.0, 1.0])\n",
        "    return samples\n",
        "\n",
        "def get_uniform_samples(n_samples, n_bits):\n",
        "    return torch.randint(0, 2, (n_samples, n_bits)).float()"
      ],
      "metadata": {
        "id": "Rl7zgm51AWk-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90ed6bd7-f17a-4af4-e26d-45a1d0e44620"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pennylane/capture/capture_operators.py:33: RuntimeWarning: PennyLane is not yet compatible with JAX versions > 0.4.28. You have version 0.5.2 installed. Please downgrade JAX to <=0.4.28 to avoid runtime errors.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class EntropyNet(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(input_dim, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "def parametric_qnee_cost(model, real_samples, uniform_samples):\n",
        "    d = 2 ** real_samples.shape[1]\n",
        "    term1 = torch.mean(model(real_samples))\n",
        "    term2 = torch.mean(torch.exp(model(uniform_samples)))\n",
        "    cost = -term1 + term2\n",
        "    rel_entropy = 1 - cost\n",
        "    entropy = np.log(d) - 1 + cost\n",
        "    return cost, entropy, rel_entropy"
      ],
      "metadata": {
        "id": "AtH7cEJLBB3O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Bell state and maximally mixed state"
      ],
      "metadata": {
        "id": "OLyIUcLAh4Y_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = EntropyNet(input_dim=2).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "\n",
        "for epoch in range(501):\n",
        "    real_samples = get_bell_samples().to(device)\n",
        "    uniform_samples = get_uniform_samples(len(real_samples), 2).to(device)\n",
        "\n",
        "    loss, entropy, rel_entropy = parametric_qnee_cost(model, real_samples, uniform_samples)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "        print(f\"Epoch {epoch}: Estimated von Neumann Entropy = {entropy.item():.4f}\")\n",
        "        print(f\"Epoch {epoch}: Estimated relative entropy between bell state and maximally mixed state = {rel_entropy.item():.4f}\")\n",
        "        print('')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gSVHqibBKeR",
        "outputId": "c93249c8-c876-4a8c-c709-660d611a7cfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: Estimated von Neumann Entropy = 1.4303\n",
            "Epoch 0: Estimated relative entropy between bell state and maximally mixed state = -0.0440\n",
            "\n",
            "Epoch 100: Estimated von Neumann Entropy = 0.0988\n",
            "Epoch 100: Estimated relative entropy between bell state and maximally mixed state = 1.2875\n",
            "\n",
            "Epoch 200: Estimated von Neumann Entropy = 0.0452\n",
            "Epoch 200: Estimated relative entropy between bell state and maximally mixed state = 1.3411\n",
            "\n",
            "Epoch 300: Estimated von Neumann Entropy = 0.0375\n",
            "Epoch 300: Estimated relative entropy between bell state and maximally mixed state = 1.3488\n",
            "\n",
            "Epoch 400: Estimated von Neumann Entropy = 0.0177\n",
            "Epoch 400: Estimated relative entropy between bell state and maximally mixed state = 1.3686\n",
            "\n",
            "Epoch 500: Estimated von Neumann Entropy = 0.0045\n",
            "Epoch 500: Estimated relative entropy between bell state and maximally mixed state = 1.3818\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Non uniform mixed state vs uniform mixed state"
      ],
      "metadata": {
        "id": "mGXDYYG_7tDN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(501):\n",
        "    real_samples = get_custom_mixed_samples(n_samples=5000).to(device)\n",
        "    uniform_samples = get_uniform_samples(len(real_samples), 2).to(device)\n",
        "\n",
        "    loss, entropy, rel_entropy = parametric_qnee_cost(model, real_samples, uniform_samples)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "        print(f\"Epoch {epoch}: Estimated entropy = {entropy.item():.4f}\")\n",
        "        print(f\"Epoch {epoch}: Relative entropy vs uniform = {rel_entropy.item():.4f}\")\n",
        "        print('')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hq_PwYxu7Ij3",
        "outputId": "3e50fb64-97d4-4cff-cd38-555e2508fd5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: Estimated entropy = 0.5957\n",
            "Epoch 0: Relative entropy vs uniform = 0.7906\n",
            "\n",
            "Epoch 100: Estimated entropy = 0.6244\n",
            "Epoch 100: Relative entropy vs uniform = 0.7619\n",
            "\n",
            "Epoch 200: Estimated entropy = 0.6080\n",
            "Epoch 200: Relative entropy vs uniform = 0.7782\n",
            "\n",
            "Epoch 300: Estimated entropy = 0.6087\n",
            "Epoch 300: Relative entropy vs uniform = 0.7776\n",
            "\n",
            "Epoch 400: Estimated entropy = 0.6340\n",
            "Epoch 400: Relative entropy vs uniform = 0.7523\n",
            "\n",
            "Epoch 500: Estimated entropy = 0.6179\n",
            "Epoch 500: Relative entropy vs uniform = 0.7684\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model complexity vs convergence"
      ],
      "metadata": {
        "id": "l8PJ-CvfE_Ex"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define five models of increasing complexity\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model_configs = {\n",
        "    \"Linear Only\": [\n",
        "        nn.Linear(2, 1)\n",
        "    ],\n",
        "    \"1 Hidden Layer (16 neurons)\": [\n",
        "        nn.Linear(2, 16),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(16, 1)\n",
        "    ],\n",
        "    \"1 Hidden Layer (32 neurons)\": [\n",
        "        nn.Linear(2, 32),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(32, 1)\n",
        "    ],\n",
        "    \"1 Hidden Layer (64 neurons)\": [\n",
        "        nn.Linear(2, 64),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(64, 1)\n",
        "    ],\n",
        "    \"2 Hidden Layers (64 → 32 neurons)\": [  # Same as the last one, for consistency\n",
        "        nn.Linear(2, 64),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(64, 32),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(32, 1)\n",
        "    ],\n",
        "}\n",
        "\n",
        "# Training loop for each model\n",
        "for name, layers in model_configs.items():\n",
        "    print(f\"\\n--- Training {name} ---\")\n",
        "\n",
        "    model = nn.Sequential(*layers).to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    for epoch in range(501):\n",
        "        real_samples = get_bell_samples().to(device)\n",
        "        uniform_samples = get_uniform_samples(len(real_samples), 2).to(device)\n",
        "\n",
        "        loss, entropy, rel_entropy = parametric_qnee_cost(model, real_samples, uniform_samples)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f\"Epoch 500: von Neumann Entropy = {entropy.item():.4f}\")\n",
        "    print(f\"Epoch 500: Relative Entropy = {rel_entropy.item():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdOciChRGnb4",
        "outputId": "dd8bfc05-eb0e-4e6e-a867-a2b303295145"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Training Linear Only ---\n",
            "Epoch 500: von Neumann Entropy = 0.9789\n",
            "Epoch 500: Relative Entropy = 0.4074\n",
            "\n",
            "--- Training 1 Hidden Layer (16 neurons) ---\n",
            "Epoch 500: von Neumann Entropy = 0.0953\n",
            "Epoch 500: Relative Entropy = 1.2910\n",
            "\n",
            "--- Training 1 Hidden Layer (32 neurons) ---\n",
            "Epoch 500: von Neumann Entropy = 0.0475\n",
            "Epoch 500: Relative Entropy = 1.3388\n",
            "\n",
            "--- Training 1 Hidden Layer (64 neurons) ---\n",
            "Epoch 500: von Neumann Entropy = -0.0403\n",
            "Epoch 500: Relative Entropy = 1.4266\n",
            "\n",
            "--- Training 2 Hidden Layers (64 → 32 neurons) ---\n",
            "Epoch 500: von Neumann Entropy = -0.0040\n",
            "Epoch 500: Relative Entropy = 1.3903\n"
          ]
        }
      ]
    }
  ]
}