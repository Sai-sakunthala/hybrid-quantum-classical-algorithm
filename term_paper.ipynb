{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN/2/lygrZZodC0ilKgyE7H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sai-sakunthala/hybrid-quantum-classical-algorithm-implementation-for-entropy-calculation/blob/main/term_paper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2GL8JfdATLI",
        "outputId": "d2f5d0ae-8665-4a95-a59a-58216dc53640"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.1/56.1 kB\u001b[0m \u001b[31m896.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m72.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m930.8/930.8 kB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m78.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m73.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m93.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install pennylane torch --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pennylane as qml\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "# Set up device\n",
        "n_qubits = 2\n",
        "n_shots = 5000\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits, shots=n_shots)\n",
        "\n",
        "@qml.qnode(dev)\n",
        "def bell_sampler():\n",
        "    qml.Hadamard(wires=0)\n",
        "    qml.CNOT(wires=[0, 1])\n",
        "    return qml.sample(qml.PauliZ(0)), qml.sample(qml.PauliZ(1))\n",
        "\n",
        "@qml.qnode(dev, interface=\"torch\")\n",
        "def bell_basis_sampler():\n",
        "    # creating bell state\n",
        "    qml.Hadamard(wires=0)\n",
        "    qml.CNOT(wires=[0, 1])\n",
        "\n",
        "    # computational basis changed to eigen basis\n",
        "    qml.CNOT(wires=[0, 1])\n",
        "    qml.Hadamard(wires=0)\n",
        "\n",
        "    return qml.sample(wires=[0, 1])\n",
        "\n",
        "def get_bell_samples():\n",
        "    samples = bell_basis_sampler()\n",
        "    return samples.to(torch.float32)\n",
        "\n",
        "def get_custom_mixed_samples(n_samples=5000):\n",
        "    samples = torch.zeros((n_samples, 2), dtype=torch.float32)\n",
        "    probs = torch.rand(n_samples)\n",
        "    samples[probs >= 0.7] = torch.tensor([1.0, 1.0])\n",
        "    return samples\n",
        "\n",
        "def get_uniform_samples(n_samples, n_bits):\n",
        "    return torch.randint(0, 2, (n_samples, n_bits)).float()"
      ],
      "metadata": {
        "id": "Rl7zgm51AWk-"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EntropyNet(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(input_dim, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "def parametric_qnee_cost(model, real_samples, uniform_samples):\n",
        "    d = 2 ** real_samples.shape[1]\n",
        "    term1 = torch.mean(model(real_samples))\n",
        "    term2 = torch.mean(torch.exp(model(uniform_samples)))\n",
        "    cost = -term1 + term2\n",
        "    rel_entropy = 1 - cost\n",
        "    entropy = np.log(d) - 1 + cost\n",
        "    return cost, entropy, rel_entropy"
      ],
      "metadata": {
        "id": "AtH7cEJLBB3O"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Bell state and maximally mixed state"
      ],
      "metadata": {
        "id": "OLyIUcLAh4Y_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = EntropyNet(input_dim=2).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "\n",
        "for epoch in range(501):\n",
        "    real_samples = get_bell_samples().to(device)\n",
        "    uniform_samples = get_uniform_samples(len(real_samples), 2).to(device)\n",
        "\n",
        "    loss, entropy, rel_entropy = parametric_qnee_cost(model, real_samples, uniform_samples)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "        print(f\"Epoch {epoch}: Estimated von Neumann Entropy = {entropy.item():.4f}\")\n",
        "        print(f\"Epoch {epoch}: Estimated relative entropy between bell state and maximally mixed state = {rel_entropy.item():.4f}\")\n",
        "        print('')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gSVHqibBKeR",
        "outputId": "c93249c8-c876-4a8c-c709-660d611a7cfb"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: Estimated von Neumann Entropy = 1.4303\n",
            "Epoch 0: Estimated relative entropy between bell state and maximally mixed state = -0.0440\n",
            "\n",
            "Epoch 100: Estimated von Neumann Entropy = 0.0988\n",
            "Epoch 100: Estimated relative entropy between bell state and maximally mixed state = 1.2875\n",
            "\n",
            "Epoch 200: Estimated von Neumann Entropy = 0.0452\n",
            "Epoch 200: Estimated relative entropy between bell state and maximally mixed state = 1.3411\n",
            "\n",
            "Epoch 300: Estimated von Neumann Entropy = 0.0375\n",
            "Epoch 300: Estimated relative entropy between bell state and maximally mixed state = 1.3488\n",
            "\n",
            "Epoch 400: Estimated von Neumann Entropy = 0.0177\n",
            "Epoch 400: Estimated relative entropy between bell state and maximally mixed state = 1.3686\n",
            "\n",
            "Epoch 500: Estimated von Neumann Entropy = 0.0045\n",
            "Epoch 500: Estimated relative entropy between bell state and maximally mixed state = 1.3818\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Non uniform mixed state vs uniform mixed state"
      ],
      "metadata": {
        "id": "mGXDYYG_7tDN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(501):\n",
        "    real_samples = get_custom_mixed_samples(n_samples=5000).to(device)\n",
        "    uniform_samples = get_uniform_samples(len(real_samples), 2).to(device)\n",
        "\n",
        "    loss, entropy, rel_entropy = parametric_qnee_cost(model, real_samples, uniform_samples)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "        print(f\"Epoch {epoch}: Estimated entropy = {entropy.item():.4f}\")\n",
        "        print(f\"Epoch {epoch}: Relative entropy vs uniform = {rel_entropy.item():.4f}\")\n",
        "        print('')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hq_PwYxu7Ij3",
        "outputId": "3e50fb64-97d4-4cff-cd38-555e2508fd5b"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: Estimated entropy = 0.5957\n",
            "Epoch 0: Relative entropy vs uniform = 0.7906\n",
            "\n",
            "Epoch 100: Estimated entropy = 0.6244\n",
            "Epoch 100: Relative entropy vs uniform = 0.7619\n",
            "\n",
            "Epoch 200: Estimated entropy = 0.6080\n",
            "Epoch 200: Relative entropy vs uniform = 0.7782\n",
            "\n",
            "Epoch 300: Estimated entropy = 0.6087\n",
            "Epoch 300: Relative entropy vs uniform = 0.7776\n",
            "\n",
            "Epoch 400: Estimated entropy = 0.6340\n",
            "Epoch 400: Relative entropy vs uniform = 0.7523\n",
            "\n",
            "Epoch 500: Estimated entropy = 0.6179\n",
            "Epoch 500: Relative entropy vs uniform = 0.7684\n",
            "\n"
          ]
        }
      ]
    }
  ]
}